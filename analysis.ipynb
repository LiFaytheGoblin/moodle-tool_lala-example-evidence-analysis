{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis of audit evidence collected with the [LaLA](https://github.com/LiFaytheGoblin/moodle-tool_lala) Moodle Plugin\n",
    "\n",
    "LaLA is a Moodle plugin to enable administrators and auditors of [Moodle Learning Analytics](https://github.com/LiFaytheGoblin/moodle-tool_lala/wiki/Moodle-Learning-Analytics) models to retrieve evidence for an audit, like the sample data collected on the Moodle instance, the calculated features and predictions made by the model. [Learn more about LaLA](https://github.com/LiFaytheGoblin/moodle-tool_lala/wiki).\n",
    "\n",
    "An [audit of an AI-integrating system](https://github.com/LiFaytheGoblin/moodle-tool_lala/wiki/Auditing) like a Moodle Learning Analytics checks different aspects of the system's utility, validity and compliance to ethical values<sup name=\"text1\">[1](#footnote1)</sup>. An audit consists of three steps<sup name=\"text1\">[1](#footnote1)</sup>: \n",
    "1. Formulating claims the system is expected to fullfill\n",
    "2. Gathering evidence to prove or disprove the claims\n",
    "3. Validating the claims using the evidence\n",
    "\n",
    "<sup name=\"footnote1\">1. Fernsel, L. and Simbeck, K. (2023). Assessing the Auditability of Learning Analytics Systems: A Framework and Case Study. Forthcoming. [↩](#text1)</sup>  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a0b473eb4f64682"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This notebook\n",
    "\n",
    "This notebook provides an example for step 3 of an audit, claim validation. In this case, the subject of the audit is [Moodle's \"Students at risk of dropping out\" model](https://docs.moodle.org/402/en/Students_at_risk_of_dropping_out). First we formulate the claim that \"Dropout predictions do not show bias against minority groups\" (Step 1). For checking this claim we used LaLA to collect evidence from a Moodle platform: We trained a dropout prediction model and retrieved the predictions it made for a test dataset (Step 2). We can now proceed to the final step and validiate the formulated claim by checking whether the model's predictions are equally accurate for both minority and majority groups (Step 3). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9414b1e8e9d271ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ⚠ Warning about the validity of this analysis ##\n",
    "This notebook functions only as an example for an analysis of evidence retrieved from LaLA. It should not be seen as part of a meaningful audit because of three reasons. Firstly and most importantly, because of the lack of useful training data, the data used for this analysis has been manipulated. Specifically, users have been randomly assigned to minority or majority groups, and they have been randomly assigned to the \"likely to drop out\" or \"not likely to drop out\" classes. The model predictions have been randomized as well. Therefore, the audit results do not reflect the reality. Secondly, this notebook only validates one claim, whereas in a real audit, auditors would formulate and validate numerous claims<sup name=\"text2\">[2](#footnote2)</sup>. Thirdly, this notebook only considers the prediction accuracy difference for one type of group, whereas a real audit would consider more metrics and more groups, depending on the identified risks of inaccurate predictions.\n",
    "\n",
    "<sup name=\"footnote2\">2. Simbeck, K. (2023). They shall be fair, transparent, and robust: Auditing learning analytics systems. AI and Ethics. https://doi.org/10.1007/s43681-023-00292-7 [↩](#text2)</sup>  \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51897a55dd03e6e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis\n",
    "\n",
    "## Import evidence\n",
    "First, we use [pandas](https://pandas.pydata.org/docs/reference/index.html) to import evidence and load it as a pandas dataframe."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6261d8a49c81e3d8"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d_predictions = pd.read_csv(\"data/predictions.csv\") # Import the predictions."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T09:09:41.402593141Z",
     "start_time": "2023-09-07T09:09:41.195015181Z"
    }
   },
   "id": "ae7afdd9db3a55bc"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sampleid  target  prediction\n",
      "0   809237-0       0           1\n",
      "1   745806-0       0           0\n",
      "2  1158255-0       0           0\n",
      "3   506686-0       0           0\n",
      "4  1977658-0       0           0\n",
      "           target  prediction\n",
      "count  453.000000  453.000000\n",
      "mean     0.163355    0.103753\n",
      "std      0.370098    0.305277\n",
      "min      0.000000    0.000000\n",
      "25%      0.000000    0.000000\n",
      "50%      0.000000    0.000000\n",
      "75%      0.000000    0.000000\n",
      "max      1.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the imported data.\n",
    "print(d_predictions.head())\n",
    "print(d_predictions.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T09:09:41.415127106Z",
     "start_time": "2023-09-07T09:09:41.404745821Z"
    }
   },
   "id": "1189c1bfbba6e0a8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Import the related user data. In this example, we chose 'lang' to be the property by which to form groups.\n",
    "d_related =  pd.read_csv(\"data/related.csv\") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T09:09:41.429055117Z",
     "start_time": "2023-09-07T09:09:41.413729944Z"
    }
   },
   "id": "dcdeb591a9a7406e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id lang\n",
      "0   809237   en\n",
      "1   745806   de\n",
      "2  1158255   de\n",
      "3   506686   de\n",
      "4  1977658   de\n",
      "lang\n",
      "en    230\n",
      "de    223\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61379/170650683.py:3: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  print(pd.value_counts(d_related['lang']))\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the imported data.\n",
    "print(d_related.head())\n",
    "print(pd.value_counts(d_related['lang']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T09:09:41.470416218Z",
     "start_time": "2023-09-07T09:09:41.421214448Z"
    }
   },
   "id": "5e47fcbcbaa13177"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explore overall model quality\n",
    "\n",
    "In this step, we use [sklearn](https://scikit-learn.org) to have a look at the overall quality of our model, as well as the quality of the model per class (\"likely to drop out\" or \"not likely to drop out\").  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a4e4cb477e0df58"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "Not likely to drop out       0.83      0.89      0.86       379\n",
      "    Likely to drop out       0.13      0.08      0.10        74\n",
      "\n",
      "              accuracy                           0.76       453\n",
      "             macro avg       0.48      0.49      0.48       453\n",
      "          weighted avg       0.72      0.76      0.74       453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_test = d_predictions['target']; # Get the truth values from the predictions dataframe.\n",
    "y_pred = d_predictions['prediction']; # Get the prediction values from the predictions dataframe.\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=['Not likely to drop out', 'Likely to drop out'])\n",
    "\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T09:09:41.752074993Z",
     "start_time": "2023-09-07T09:09:41.425700896Z"
    }
   },
   "id": "351c7b6b1a80c560"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fairness analysis\n",
    "\n",
    "Next, we use [fairlearn](https://fairlearn.org) to judge the quality of the results differentiated by group. Groups are defined by the attribute a user has entered as \"lang\" (language). While fairlearn provides many possible fairness metrics, for the simplicity of this audit, we just compare the accuracy by group. A true audit would make a risk-based selection of fairness metrics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24d163d5f30e83f1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Assign to each d_predictions the fitting lang\n",
    "\n",
    "d_predictions['id'] = d_predictions['sampleid'].str.split('-').str[0] # Get only the id part of the sampleid\n",
    "\n",
    "d_predictions['id'] = d_predictions['id'].astype(int)\n",
    "d_related['id'] = d_related['id'].astype(int)\n",
    "\n",
    "id_to_lang = d_related.set_index('id')['lang'].to_dict()  # Create a mapping dictionary\n",
    "\n",
    "d_predictions['lang'] = d_predictions['id'].map(id_to_lang)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T09:09:41.752317879Z",
     "start_time": "2023-09-07T09:09:41.746568076Z"
    }
   },
   "id": "b33ae9f2627c9bf3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linda/Repositories/moodle-tool_lala-example-evidence-analysis/venv/lib/python3.10/site-packages/fairlearn/metrics/_disaggregated_result.py:235: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  mf = mf.applymap(lambda x: x if np.isscalar(x) else np.nan)\n",
      "/home/linda/Repositories/moodle-tool_lala-example-evidence-analysis/venv/lib/python3.10/site-packages/fairlearn/metrics/_disaggregated_result.py:235: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  mf = mf.applymap(lambda x: x if np.isscalar(x) else np.nan)\n",
      "/home/linda/Repositories/moodle-tool_lala-example-evidence-analysis/venv/lib/python3.10/site-packages/fairlearn/metrics/_disaggregated_result.py:235: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  mf = mf.applymap(lambda x: x if np.isscalar(x) else np.nan)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from fairlearn.metrics import MetricFrame\n",
    "\n",
    "metrics = { \"accuracy\": accuracy_score } # Select fairness metrics (accuracy score)\n",
    "\n",
    "mf = MetricFrame(metrics=metrics, y_true=y_test, y_pred=y_pred, sensitive_features=d_predictions['lang']) # Calculate the selected fairness metrics."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T09:09:41.791822784Z",
     "start_time": "2023-09-07T09:09:41.748584605Z"
    }
   },
   "id": "8e48b05687e1255c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[<Axes: title={'center': 'accuracy'}, xlabel='lang'>,\n        <Axes: xlabel='lang'>]], dtype=object)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 600x200 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the calculated fairness metrics.\n",
    "mf.by_group.plot.bar(\n",
    "    subplots=True,\n",
    "    layout=[1, 2],\n",
    "    legend=False,\n",
    "    figsize=[6, 2]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T09:09:42.141098365Z",
     "start_time": "2023-09-07T09:09:41.771365860Z"
    }
   },
   "id": "2646ee79297c09e5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "accuracy    0.023474\ndtype: float64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy comparison: Calculate the accuracy and count difference\n",
    "mf.difference()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T09:09:42.147777303Z",
     "start_time": "2023-09-07T09:09:42.144147500Z"
    }
   },
   "id": "2b3638b97810cfdc"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "accuracy    0.969565\ndtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy comparison: Calculate the accuracy and count ratio\n",
    "mf.ratio()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T09:09:42.154824100Z",
     "start_time": "2023-09-07T09:09:42.148958282Z"
    }
   },
   "id": "a318753a22f21b80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Interpretation\n",
    "\n",
    "As we can see from the plots as well as the difference and ratio calculations, the accuracies for both available groups 'en' and 'de' are about the same. Therefore we can conclude that the model does not show any bias against minority groups."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61ee05578abf80cc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
